from numpy import array
from math import log2
from json import load
from os.path import join, exists
from os import makedirs, getcwd
from pickle import dump, load
from bz2 import BZ2File
from pandas import DataFrame
from infre.tools import apriori
from infre import retrieval


from infre.models import BaseIRModel
class SetBased(BaseIRModel):
    def __init__(self, collection=None):
        
        # inherit from base model
        super().__init__(collection)

        # model name
        self.model = self._model()

        # docs tensor holds documents representation in vector space of each query
        # self.dtm_tensor = []


    def _model(self): return __class__.__name__
    

    def tsf_idf(self, tf_ij, idf):
        ########## each column corresponds to a document #########
        return tf_ij * idf.reshape(-1, 1)
    

    def fit(self, queries, mf=1):

        # inverted index of collection documents
        inv_index = self.collection.inverted_index

        # for each query
       
        for i, query in enumerate(queries, start=1):
        
            print(f"=> Query {i} of {len(queries)}")

            # apply apriori to find frequent termsets
            freq_termsets = apriori(query, inv_index, min_freq=mf)
            
            print(f"Query length: {len(query)} | Frequent Termsets: {len(freq_termsets)}")

            # vectorized query generated by apriori
            idf_vec = self.query2vec(freq_termsets) # (1 X len(termsets)) vector
            
            # vectorized documents generated by apriori query
            tsf_ij = self.termsets2vec(freq_termsets) # (len(termsets) X N) matrix
            
            # clucnky solution for polymorphism
            # try:
            #    tnw = retrieval.tnw(freq_termsets, self.nwk)
            # except AttributeError:
            #     tnw = 1
            
            # represent documents in vector space
            # dtm = self.doc_vectorizer(tsf_ij, idf_vec)
            
            # keep local copy for dtm of every document
            # self.dtm_tensor += [dtm]
            
            # append matrix representation of termset frequency per document
            self._docs2vec.append(tsf_ij)

            # append vector query generated by apriori
            self._q2vec.append(idf_vec)

            # print(f'{(time() - start):.2f} secs.\n') TODO: loadbar
        return self


    def evaluate(self, relevant):
        
        num_of_q = len(self._q2vec)

        # for each query and (dtm, relevant) pair
        for i, (qv, dv, rel) in enumerate(zip(self._q2vec, self._docs2vec, relevant)):
            
            # all the money function
            # document - termset matrix
            dtsm = self.tsf_idf(dv, qv)

            # cosine similarity between query and every document
            qd_sims = self.qd_similarities(qv, dtsm)

            # rank them in desc order
            retrieved_docs = self.rank_documents(qd_sims)

            # precision | recall of ranking
            pre, rec = retrieval.precision_recall(retrieved_docs.keys(), rel)

            print(f"=> Evaluating Query {i+1} of {num_of_q}")
            print(f'Precision: {pre:.3f} | Recall: {rec:.3f}')

            self.precision.append(round(pre, 3))
            self.recall.append(round(rec, 3))

        return array(self.precision), array(self.recall)

    
    def save_results(self, *args):

        # pre, rec = args if args else self.precision, self.recall
        if args:
            pre, rec = args
        else:
            pre, rec = self.precision, self.recall
     
        df = DataFrame(list(zip(pre, rec)), columns=["precision", "recall"])
      
        path = join(getcwd(), 'saved_models', self.model, 'results')

        if not exists(path): makedirs(path)

        df.to_excel(join(path, f'{self.model.lower()}.xlsx'))

        return self


    def save_model(self, path, name='config.model'):
        
        # define indexes path
        dir = join(getcwd(), path, self.model)
   
        if not exists(dir): makedirs(dir)

        path = join(dir, name)

        try:
            with BZ2File(path, 'wb') as config_model:
                dump(self, config_model)

        except FileNotFoundError:
                FileNotFoundError


    def load_model(self, **kwargs):

        # define indexes path
        try:
            path = join(getcwd(), kwargs['dir'], self.model, kwargs['name'])
        except KeyError:
            raise KeyError

        try:
            with BZ2File(path, 'rb') as config_model:

                return load(config_model)

        except FileNotFoundError:
                raise FileNotFoundError