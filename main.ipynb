{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInvertedIndexFromFile(file, postingl):\n",
    "    with open(file, 'r') as fd:\n",
    "        # list containing every word in text document\n",
    "        text = fd.read().split()\n",
    "        uninque_terms = []\n",
    "        termFreq = []\n",
    "        for term in text:\n",
    "            if term not in uninque_terms:\n",
    "                uninque_terms.append(term)\n",
    "                termFreq.append(text.count(term))\n",
    "            if term not in postingl:\n",
    "                postingl.append(term)\n",
    "                postingl.append([file, text.count(term)])\n",
    "            else:\n",
    "                existingtermindex = postingl.index(term)\n",
    "                if file not in postingl[existingtermindex + 1]:\n",
    "                    postingl[existingtermindex + 1].extend([file, text.count(term)])\n",
    "    # print(len(uninque_terms)) [oros , ari8mois emfanisis]\n",
    "    # print(termFreq)\n",
    "    return (uninque_terms, termFreq, postingl, len(text))\n",
    "\n",
    "    ###############################lemmas################################\n",
    "    # Weight_of_edge(i,j) = No.occurencies_of_i * No.occurencies_of_j   #\n",
    "    #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41202006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runIt(filename, ans,window_flag, window_size, sen_par_flag, par_window_size,per_window,dot_split,file_sum_mat):\n",
    "    print(filename)\n",
    "    temp = createInvertedIndexFromFile(filename, postinglist)\n",
    "    \n",
    "    if window_flag:\n",
    "        try:\n",
    "            adjmat = CreateAdjMatrixFromInvIndexWithWindow(temp[0],filename,window_size,per_window,dot_split)\n",
    "        except MemoryError:\n",
    "            sizeof_err_matrix = sys.getsizeof(adjmat)\n",
    "            print(sizeof_err_matrix)\n",
    "            exit(-1)        \n",
    "    elif sen_par_flag:\n",
    "        try:\n",
    "            adjmat = CreateAdjMatrixFromInvIndexWithSenParWindow(temp[0],filename,window_size, par_window_size,dot_split)\n",
    "        except MemoryError:\n",
    "            sizeof_err_matrix = sys.getsizeof(adjmat)\n",
    "            print(sizeof_err_matrix)\n",
    "            exit(-1) \n",
    "    else:\n",
    "        try:\n",
    "            adjmat = CreateAdjMatrixFromInvIndex(temp[0], temp[1])\n",
    "        except MemoryError:\n",
    "            sizeof_err_matrix = sys.getsizeof(adjmat)\n",
    "            print(sizeof_err_matrix)\n",
    "            exit(-1)\n",
    "    #if int(filename[9:]) in bucket_list[5]:\n",
    "     #   file_sum_mat = calculateSummationMatrix(adjmat,filename,file_sum_mat,temp[0],window_size)\n",
    "    #######################\n",
    "    try:\n",
    "        gr = graphUsingAdjMatrix(adjmat, temp[0])\n",
    "        docinfo.append([filename, temp[3]])\n",
    "    except MemoryError:\n",
    "        sizeof_err_matrix = sys.getsizeof(adjmat)\n",
    "        print(sizeof_err_matrix)\n",
    "        exit(-1)\n",
    "    with open('docinfo.dat', 'a') as file_handler:\n",
    "        file_handler.write('%s %s \\n' % (filename, temp[3]))\n",
    "    file_handler.close()\n",
    "    # print(\"----------------Using networkx method:---------------\")\n",
    "    # calculate the difference between min and max similarity and use it to prune our graph\n",
    "    kcore = nx.Graph()\n",
    "    kcore_nodes = []\n",
    "    prunedadjm = nx.to_numpy_array(kcore)\n",
    "    #\tcorebool --> not used(Can change to apply union graph penalty or not)\n",
    "    #\tsplitfiles --> Window based splitting methods will be used if true(Exists because we use GSB in our experiments which doesnt require splitting)\n",
    "    #\tsen_par_flag --> if true sentence paragraph method will be used\n",
    "    #\tdot_split --> if true we will split according to \".\" using nltk's tokenize with punkt\n",
    "    #\twindow_size --> The size of window when we are splitting using constant windows. If it is equal to 0\n",
    "    #\t\t\tper_window will be used instead.(per_window is the percentage of the text we will use)\n",
    "    #\tper_window --> A number between 0-1. 0 is 0% of the text while 1 is 100%. It is used to calculate the\n",
    "    #\t\t\twindow size when using file length percentage based splitting.\n",
    "    #\tpar_window_size --> Only used when sen_par_flag is true. It is the window size that corresponds to the paragraph level\n",
    "    #\tinvfilename --> filename of the inverted index that will be constructed.\n",
    "    #\n",
    "    # Flag Hierarchy:\n",
    "    #\n",
    "    #\tsplitfiles >> sen_par_flag >> dot_split >> corebool(doesnt do anyting yet)\n",
    "    #\n",
    "    #\tif splitfiles is false then we use gsb\n",
    "    #\n",
    "    #\tif sen_par_flag is true we use sentence/paragraph splitting\n",
    "    #\t\tif dot_split is true the sentence portion of the adjmatrix will be split according to \".\"\n",
    "    #\t\tif dot split is false the file will be split according to window size(the sentence part only)\n",
    "    #\t\t\tif window size is 0 then the sentence portion of the adjmatrix will be generated according to percentage of the file(based on per_window)\n",
    "    #\t\t\tif window size is a positive integer the sentence portion of the adjmatrix will be generated according to that integer(constant window splitting)\n",
    "    #\t\tFor the paragraph part we will be using constant window splitting according to par_window_size.(always)\n",
    "    #\tif sen_par_flag is false then we use regular splitting accoding to the rest of the flags/values\n",
    "    #\t\tif dot_split is true then we use splitting according to \".\" using nltk and punkt\n",
    "    #\t\tif dot split is false the file will be split according to window size\n",
    "    #\t\t\tif window size is 0 then the file will be split according to percentage of the file(based on per_window)\n",
    "    #\t\t\tif window size is a positive integer the file will be split according to that integer(constant window splitting)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # With current flags:\n",
    "    #\n",
    "    #\tX=1 --> penalty on union graph splitting using percentages\n",
    "    #\tX=2 --> GSB\n",
    "    #\tX=3 --> penalty on union graph splitting using percentages\n",
    "    #\tX=4 --> penalty on union graph splitting using \".\" ISSUE:IF nltk is not installed, BY PASS: At menu 2: input one of existing indexes\n",
    "    #\tX=5 --> penalty on union graph splitting using constant window size\n",
    "    #\tX=6 --> penalty on union graph splitting using sentence/paragraph windows\n",
    "    #\n",
    "    #   !This is where we add methods to improve the graph such as core/truss decomposition, pruning, methods for important nodes. !\n",
    "\n",
    "    #   NOTE: this main uses penalty on union graph (see lines 65,70,77 - uniongraph function) to punish frequent edges.\n",
    "    if ans == 1:\n",
    "\n",
    "        # By creating new graph we can translate it easily to the respective adj matrix\n",
    "        # without calculating each edge weight separtly. It returns a pruned GRAPH\n",
    "        print(\"Calculating without maincore:\")\n",
    "        prunedadjm = adjmat\n",
    "        kcore_nodes = []\n",
    "        #stopwordsStats(kcore,temp[0],filename)\n",
    "        #print(nx.number_of_nodes(kcore))\n",
    "        #print(len(kcore))\n",
    "        #print(kcore.degree())\n",
    "    if ans == 3:\n",
    "        print(\"Calculating without maincore:\")\n",
    "        prunedadjm = adjmat\n",
    "        kcore_nodes =[]\n",
    "    if ans == 4 :\n",
    "        print(\"Calculating without maincore:\")\n",
    "        prunedadjm = adjmat\n",
    "        kcore_nodes =[]\n",
    "            \n",
    "    ###################TEST####################\n",
    "    if ans == 5 :\n",
    "        print(\"Calculating without maincore:\")\n",
    "        prunedadjm = adjmat\n",
    "        kcore_nodes =[]\n",
    "\t\t\n",
    "    if ans == 6 :\n",
    "        print(\"Calculating without maincore:\")\n",
    "        prunedadjm = adjmat\n",
    "        kcore_nodes =[]\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    if ans == 2:\n",
    "        print(\"Calculating without maincore:\")\n",
    "        prunedadjm = adjmat\n",
    "        kcore_nodes =[]\n",
    "    term_freq = temp[1]\n",
    "    # print(term_freq)\n",
    "    return adjmat, temp[0], gr, term_freq, kcore_nodes, prunedadjm, file_sum_mat  # adjacency matrix terms list , graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25947b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import expanduser, join, getsize\n",
    "from operator import itemgetter\n",
    "\n",
    "home = expanduser('~')\n",
    "path = f'{home}/Desktop/thesis_code/data/test_docs'\n",
    "\n",
    "file_list = []\n",
    "for item in listdir(path):\n",
    "    name = join(path, item)\n",
    "    if getsize(name) == 0:\n",
    "        print('%s is empty:' % name)\n",
    "        os.remove(name)\n",
    "    else:\n",
    "        #preproccess(name) #possible bug here uncomment this line if the files are used for the first time\n",
    "        file_list.append([name, getsize(name)])\n",
    "file_list = sorted(file_list, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ce02cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test3', 102],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test', 78],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test1', 78],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test5', 72],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test2', 67]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a95510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test3', 102],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test', 78],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test1', 78],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test5', 72],\n",
       " ['C:\\\\Users\\\\giwrg/Desktop/thesis_code/data/test_docs\\\\test2', 67]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    \n",
    "    filename = file[0]\n",
    "    # print(\"=========================For file = %s==================== \" % name)    \n",
    "    gr = runIt(name, int(X),splitfiles, window_size, sen_par_flag, par_window_size,per_window,dot_split,file_sum_mat)\n",
    "    # write doc info to file\n",
    "    adjmatrix = gr[0]\n",
    "    terms = gr[1]\n",
    "    graph = gr[2]\n",
    "    term_freq = gr[3]\n",
    "    maincore = gr[4]\n",
    "    prunedadjm = gr[5]\n",
    "    file_sum_mat = gr[6]\n",
    "    #getGraphStats(graph,name,True, True)\n",
    "\n",
    "    try:\n",
    "        ug = uniongraph(terms, term_freq, adjmatrix, collection_terms, union_graph_termlist_id, union_graph, id,\n",
    "                        collection_term_freq, maincore, kcorebool=corebool)\n",
    "\n",
    "    except MemoryError:\n",
    "        sizeofgraph = sys.getsizeof(union_graph.edge) + sys.getsizeof(union_graph.node)\n",
    "        print(sizeofgraph)\n",
    "        exit(-1)\n",
    "    #######################\n",
    "    collection_terms = ug[2]\n",
    "    #######################\n",
    "    id = ug[5]\n",
    "    union_graph = ug[4]\n",
    "    collection_term_freq = ug[6]\n",
    "\n",
    "    un_end = time.time()\n",
    "    sumtime += (un_end - un_start) / 60\n",
    "    #print('time spent on union graph = %f with adj matrix size %d' % (((un_end - un_start) / 60), len(adjmatrix)))\n",
    "    #print('elapsed time = %f' % sumtime)\n",
    "\n",
    "    del graph\n",
    "    del adjmatrix\n",
    "    del prunedadjm\n",
    "    del maincore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
